# Task 2 – Reinforcement Learning using PPO in ChefHat Environment

## Student Information
- Module: 7043SCN – Generative AI and Reinforcement Learning
- Task: Task 2 – Reinforcement Learning Implementation
- Student ID: 16364251
- 16364251 mod 7 = 1
- ID mod 7 = 0 or 1 → Opponent Modelling Variant
- Algorithm Used: Proximal Policy Optimization (PPO)
- Environment: ChefHat Gym
- Framework: Stable-Baselines3
- Language: Python

---

## Task 2 Topic Selection

Based on my Student ID (16364251), the assigned topic for Task 2 was to implement a Reinforcement Learning agent using the Proximal Policy Optimization (PPO) algorithm in the ChefHat Gym environment.

This project successfully implements the PPO algorithm to train an intelligent agent that learns optimal strategies through interaction with the environment.

---

## Project Overview

This project implements a Reinforcement Learning agent using the Proximal Policy Optimization (PPO) algorithm in the ChefHat Gym environment.

The objective is to train an intelligent agent that learns optimal strategies through interaction with the environment and improves its performance over time using reward-based learning.

The agent observes the environment, takes actions, receives rewards, and updates its policy to maximize long-term rewards.

---

## Tools and Libraries Used

The following tools and libraries were used:

- Python
- Jupyter Notebook
- Stable-Baselines3
- Gym / Gymnasium
- NumPy
- Matplotlib
- PyTorch
- Anaconda Environment


---

## Dataset

The dataset used in this project is:

Dataset.pkl.csv

This dataset contains simulated ChefHat game data generated from the ChefHat Gym environment. It is used for training and evaluation of the reinforcement learning agent.

---

## Methodology

The following steps were performed:

1. Installed and configured the ChefHat Gym environment.
2. Created the reinforcement learning environment.
3. Initialized the PPO agent using Stable-Baselines3.
4. Trained the agent using interaction with the environment.
5. Saved the trained model.
6. Generated performance graphs.
7. Evaluated the learning performance.

---

## PPO Algorithm

Proximal Policy Optimization (PPO) is a policy gradient method used in reinforcement learning.

Advantages of PPO:

- Stable training
- Efficient learning
- Good performance in complex environments
- Widely used in modern reinforcement learning applications

---

## Results

The following performance metrics were obtained:

- Learning Curve
- Average Reward Improvement
- Win Rate Analysis
- Episode Performance

The graphs show that the agent improves its performance over time.

---

## Outputs

The outputs folder contains:

- learning_curve.png
- avg_reward.png
- win_rate.png
- episode_length.png

These graphs demonstrate the learning progress of the PPO agent.

---

## Trained Model

The trained PPO model is saved as:

chefhat_ppo_model.zip

This file contains the learned policy and can be reused without retraining.

---

## How to Run the Project

Step 1: Install required libraries

Step 2: Open Jupyter Notebook

 
Step 3: Run all cells to train and evaluate the agent.

---

## Conclusion

This project successfully implemented a PPO reinforcement learning agent in the ChefHat Gym environment.

The agent learned optimal strategies through interaction with the environment, and performance improved over time as shown in the output graphs.

This demonstrates the effectiveness of reinforcement learning using PPO.

---

## Repository

GitHub repository contains all required files including code, dataset, trained model, outputs, and documentation.

---

## Author

Student ID: 16364251  
Coventry University
Module: 7043SCN – Generative AI and Reinforcement Learning

